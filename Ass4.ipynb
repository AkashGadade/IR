{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2317b9e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4e7a1d4",
   "metadata": {},
   "source": [
    "#### Assignment No.4\n",
    "Perform text classification using Naive Bayes/Logistic\n",
    "Regression/ Support Vector Machines /Decision Tree\n",
    "Classifier. Use dataset \"Economic news article tone and\n",
    "relevance\" news articles, which were tagged as relevant or not\n",
    "relevant to the US Economy. Keep the required columns and\n",
    "save it in a dataframe. Explore the process of training and\n",
    "testing text classifier for this dataset and analyse the\n",
    "performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32699021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gadad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gadad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gadad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gadad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gadad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c9d9a",
   "metadata": {},
   "source": [
    "### 1.Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7991ac6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>positivity</th>\n",
       "      <th>positivity:confidence</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance:confidence</th>\n",
       "      <th>articleid</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>positivity_gold</th>\n",
       "      <th>relevance_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_unit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842613455</th>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 17:48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.640</td>\n",
       "      <td>wsj_398217788</td>\n",
       "      <td>8/14/91</td>\n",
       "      <td>Yields on CDs Fell in the Latest Week</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842613456</th>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 16:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000</td>\n",
       "      <td>wsj_399019502</td>\n",
       "      <td>8/21/07</td>\n",
       "      <td>The Morning Brief: White House Seeks to Limit ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Wall Street Journal Online&lt;/br&gt;&lt;/br&gt;The Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842613457</th>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 1:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000</td>\n",
       "      <td>wsj_398284048</td>\n",
       "      <td>11/14/91</td>\n",
       "      <td>Banking Bill Negotiators Set Compromise --- Pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842613458</th>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 2:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.675</td>\n",
       "      <td>wsj_397959018</td>\n",
       "      <td>6/16/86</td>\n",
       "      <td>Manager's Journal: Sniffing Out Drug Abusers I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The statistics on the enormous costs of employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842613459</th>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 17:48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.640</td>\n",
       "      <td>wsj_398838054</td>\n",
       "      <td>10/4/02</td>\n",
       "      <td>Currency Trading: Dollar Remains in Tight Rang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "_unit_id                                                               \n",
       "842613455    False   finalized                   3     12/5/15 17:48   \n",
       "842613456    False   finalized                   3     12/5/15 16:54   \n",
       "842613457    False   finalized                   3      12/5/15 1:59   \n",
       "842613458    False   finalized                   3      12/5/15 2:19   \n",
       "842613459    False   finalized                   3     12/5/15 17:48   \n",
       "\n",
       "           positivity  positivity:confidence relevance  relevance:confidence  \\\n",
       "_unit_id                                                                       \n",
       "842613455         3.0                 0.6400       yes                 0.640   \n",
       "842613456         NaN                    NaN        no                 1.000   \n",
       "842613457         NaN                    NaN        no                 1.000   \n",
       "842613458         NaN                 0.0000        no                 0.675   \n",
       "842613459         3.0                 0.3257       yes                 0.640   \n",
       "\n",
       "               articleid      date  \\\n",
       "_unit_id                             \n",
       "842613455  wsj_398217788   8/14/91   \n",
       "842613456  wsj_399019502   8/21/07   \n",
       "842613457  wsj_398284048  11/14/91   \n",
       "842613458  wsj_397959018   6/16/86   \n",
       "842613459  wsj_398838054   10/4/02   \n",
       "\n",
       "                                                    headline  positivity_gold  \\\n",
       "_unit_id                                                                        \n",
       "842613455              Yields on CDs Fell in the Latest Week              NaN   \n",
       "842613456  The Morning Brief: White House Seeks to Limit ...              NaN   \n",
       "842613457  Banking Bill Negotiators Set Compromise --- Pl...              NaN   \n",
       "842613458  Manager's Journal: Sniffing Out Drug Abusers I...              NaN   \n",
       "842613459  Currency Trading: Dollar Remains in Tight Rang...              NaN   \n",
       "\n",
       "           relevance_gold                                               text  \n",
       "_unit_id                                                                      \n",
       "842613455             NaN  NEW YORK -- Yields on most certificates of dep...  \n",
       "842613456             NaN  The Wall Street Journal Online</br></br>The Mo...  \n",
       "842613457             NaN  WASHINGTON -- In an effort to achieve banking ...  \n",
       "842613458             NaN  The statistics on the enormous costs of employ...  \n",
       "842613459             NaN  NEW YORK -- Indecision marked the dollar's ton...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Economic_News.csv',encoding=('ISO-8859-1'),index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ef5c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8000 entries, 842613455 to 830985636\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   _golden                8000 non-null   bool   \n",
      " 1   _unit_state            8000 non-null   object \n",
      " 2   _trusted_judgments     8000 non-null   int64  \n",
      " 3   _last_judgment_at      8000 non-null   object \n",
      " 4   positivity             1420 non-null   float64\n",
      " 5   positivity:confidence  3775 non-null   float64\n",
      " 6   relevance              8000 non-null   object \n",
      " 7   relevance:confidence   8000 non-null   float64\n",
      " 8   articleid              8000 non-null   object \n",
      " 9   date                   8000 non-null   object \n",
      " 10  headline               8000 non-null   object \n",
      " 11  positivity_gold        0 non-null      float64\n",
      " 12  relevance_gold         0 non-null      float64\n",
      " 13  text                   8000 non-null   object \n",
      "dtypes: bool(1), float64(5), int64(1), object(7)\n",
      "memory usage: 882.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7d2bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 14)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "no          6571\n",
       "yes         1420\n",
       "not sure       9\n",
       "Name: relevance, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df.shape) # Number of rows (instances) and columns in the dataset\n",
    "df[\"relevance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1b9308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no          0.821375\n",
       "yes         0.177500\n",
       "not sure    0.001125\n",
       "Name: relevance, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"relevance\"].value_counts()/df.shape[0]# Class distribution in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2ad87",
   "metadata": {},
   "source": [
    "There is an imbalance in the data with not relevant being 82% in the dataset. That is, most of the articles are not relevant to US Economy, which makes sense in a real-world scenario, as news articles discuss various topics. We should keep this class imbalance mind when interpreting the classifier performance later. Let us first convert the class labels into binary outcome variables for convenience. 1 for Yes (relevant), and 0 for No (not relevant), and ignore \"Not sure\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bafbc",
   "metadata": {},
   "source": [
    "### 2.Label Encodeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdcfbf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping for label encoding\n",
    "label_mapping = {'no': 0, 'yes': 1}\n",
    "\n",
    "# Apply label encoding to the 'label' column\n",
    "df['label_num'] = df['relevance'].map(label_mapping)\n",
    "df = df[[\"text\",\"label_num\"]] # Let us take only the two columns we need.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46de5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert label to a numerical variable\n",
    "# df = df[df.relevance != \"not sure\"] # removing the data where we don't want relevance=\"not sure\".\n",
    "# df.shape\n",
    "# df['relevance'] = df.relevance.map({'yes':1, 'no':0}) # relevant is 1, not-relevant is 0. \n",
    "# df = df[[\"text\",\"relevance\"]] # Let us take only the two columns we need.\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dfbdddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_unit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842613455</th>\n",
       "      <td>new york yields certificates deposit offered m...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842613456</th>\n",
       "      <td>wall street journal onlinebrbrthe morning brie...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842613457</th>\n",
       "      <td>washington effort achieve banking reform senat...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842613458</th>\n",
       "      <td>statistics enormous costs employee drug abuse ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842613459</th>\n",
       "      <td>new york indecision marked dollars tone trader...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  label_num\n",
       "_unit_id                                                               \n",
       "842613455  new york yields certificates deposit offered m...        1.0\n",
       "842613456  wall street journal onlinebrbrthe morning brie...        0.0\n",
       "842613457  washington effort achieve banking reform senat...        0.0\n",
       "842613458  statistics enormous costs employee drug abuse ...        0.0\n",
       "842613459  new york indecision marked dollars tone trader...        1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19273a",
   "metadata": {},
   "source": [
    "### 3.Define a Preprocessing Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "372b9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(Message):\n",
    "    # Convert text to lowercase\n",
    "    Message = Message.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    Message = re.sub(r'[^a-z\\s]', '', Message)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens =nltk.word_tokenize(Message)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "df['text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeaf018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "x=df['text']\n",
    "y=df['label_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "541f206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_unit_id\n",
      "842613455    new york yields certificates deposit offered m...\n",
      "842613456    wall street journal onlinebrbrthe morning brie...\n",
      "842613457    washington effort achieve banking reform senat...\n",
      "842613458    statistics enormous costs employee drug abuse ...\n",
      "842613459    new york indecision marked dollars tone trader...\n",
      "                                   ...                        \n",
      "830985632    secretary commerce charles w sawyer said yeste...\n",
      "830985633    us stocks inched last week overcoming concern ...\n",
      "830985634    ben bernanke cleared key hurdle thursday confi...\n",
      "830985635    white houses push contract many federal functi...\n",
      "830985636    new york april automobile stocks put best show...\n",
      "Name: text, Length: 7991, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c67eb9",
   "metadata": {},
   "source": [
    "### 4.Feature Extraction and Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "100ff02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have the features (X) and labels (y) from your dataset\n",
    "# Apply TF-IDF Vectorization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform([preprocess_text(Message) for Message in x])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee8bdd3",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7c786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8136335209505942\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.99      0.90      1302\n",
      "         1.0       0.48      0.05      0.09       297\n",
      "\n",
      "    accuracy                           0.81      1599\n",
      "   macro avg       0.65      0.52      0.49      1599\n",
      "weighted avg       0.76      0.81      0.75      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate the model\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecacd54e",
   "metadata": {},
   "source": [
    "### Taking User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a44f04fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your message here: new york indecision marked dollars tone trader\n",
      "Predicted Class: No\n"
     ]
    }
   ],
   "source": [
    "# Assuming `new_message` is the new email you want to classify\n",
    "new_message = input(\"Your message here: \") # Replace with your actual message\n",
    "preprocessed_message = preprocess_text(new_message)\n",
    "tfidf_vectorized_message = tfidf_vectorizer.transform([preprocessed_message])\n",
    "\n",
    "prediction = nb_classifier.predict(tfidf_vectorized_message)\n",
    "print(f\"Predicted Class: {'yes' if prediction == 1 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080da16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
